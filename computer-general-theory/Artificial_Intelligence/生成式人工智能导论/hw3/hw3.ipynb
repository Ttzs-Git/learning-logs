{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!pip3 install openai\n",
    "!pip3 install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "import openai\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 设置你的 OPENAI API 密钥，这里以阿里云 DashScope API为例进行演示\n",
    "OPENAI_API_KEY = \"sk-tqeffovhnxuhojxzzbitlzhgpfguaqredvigjzjjybbumvsf\"\n",
    "client = openai.OpenAI(\n",
    "    api_key=OPENAI_API_KEY,\n",
    "    base_url=\"https://api.siliconflow.cn/v1\",  # 使用阿里云大模型API\n",
    ")\n",
    "\n",
    "# 检查是否正确设置了 API\n",
    "# 如果一切正常，你将看到 \"API 设置成功！！\"\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "            model=\"deepseek-ai/DeepSeek-R1\",  # 使用阿里云 DashScope 的模型\n",
    "            messages=[{'role': 'user', 'content': \"测试\"}],  # 设置一个简单的测试消息\n",
    "            max_tokens=1,\n",
    "    )\n",
    "    print(\"API 设置成功！！\")  # 输出成功信息\n",
    "except Exception as e:\n",
    "    print(f\"API 可能有问题，请检查：{e}\")  # 输出详细的错误信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: 在此处输入用于摘要的提示词\n",
    "prompt_for_summarization = \"请为以下文章生成一个简洁的摘要，要求如下：提取核心观点和关键信息；保持逻辑清晰，语言简练；避免添加个人观点或额外解释；如果文章涉及数据或研究结果，请保留重要数据;生成的内容请保持完整\"\n",
    "\n",
    "# 重置对话的函数\n",
    "def reset() -> List:\n",
    "    return []\n",
    "\n",
    "# 调用模型生成摘要的函数\n",
    "def interact_summarization(prompt: str, article: str, temp=1.0) -> List[Tuple[str, str]]:\n",
    "    '''\n",
    "    * 参数:\n",
    "      - prompt: 我们在此部分中使用的提示词\n",
    "      - article: 需要摘要的文章\n",
    "      - temp: 模型的温度参数。温度用于控制聊天机器人的输出。温度越高，响应越具创造性。\n",
    "    '''\n",
    "    input = f\"{prompt}\\n{article}\"\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"deepseek-ai/DeepSeek-R1\",  # 使用阿里云 DashScope 的模型\n",
    "        messages=[{'role': 'user', 'content': input}],\n",
    "        temperature=temp,\n",
    "        max_tokens=200,  # 你需要注意到这里设置了文本的长度上限。\n",
    "    )\n",
    "\n",
    "    return [(input, response.choices[0].message.content)]\n",
    "\n",
    "# 导出整个对话内容的函数\n",
    "def export_summarization(chatbot: List[Tuple[str, str]], article: str) -> None:\n",
    "    '''\n",
    "    * 参数:\n",
    "      - chatbot: 模型的对话记录，存储在元组列表中\n",
    "      - article: 需要摘要的文章\n",
    "    '''\n",
    "    target = {\"chatbot\": chatbot, \"article\": article}\n",
    "    with open(\"files/part1.json\", \"w\") as file:\n",
    "        json.dump(target, file)\n",
    "\n",
    "# 生成 Gradio 的UI界面\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# 第1部分：摘要\\n填写任何你喜欢的文章，让聊天机器人为你总结！\")\n",
    "    chatbot = gr.Chatbot()\n",
    "    prompt_textbox = gr.Textbox(label=\"提示词\", value=prompt_for_summarization, visible=False)\n",
    "    article_textbox = gr.Textbox(label=\"文章\", interactive=True, value=\"Transformer是谷歌研究人员开发的一种深度学习架构，基于2017 年论文《Attention Is All You Need》中提出的多头注意力机制。[ 1 ]文本被转换为称为token的数值表示，每个 token 通过从词嵌入表中查找转换为向量。[ 1 ]在每一层，每个token都通过并行多头注意力机制在上下文窗口范围内与其他（未屏蔽的）token进行语境化，从而放大关键token的信号，减弱不太重要的 token。Transformer 的优势在于没有循环单元，因此所需的训练时间比早期的循环神经架构(RNN)（例如长短期记忆(LSTM)）要少。[ 2 ]后来的变体已被广泛用于在大型（语言）数据集上训练大型语言模型(LLM) 。[ 3 ]Transformer 最初是作为对以前机器翻译 架构的改进而开发的，[ 4 ] [ 5 ]但此后已发现了许多应用。它们用于大规模自然语言处理、计算机视觉（视觉变换器）、强化学习、[ 6 ] [ 7 ] 音频、[ 8 ] 多模态学习、机器人技术、[ 9 ]甚至下棋。[ 10 ]它还导致了预训练系统的发展，例如生成式预训练 Transformer（GPT）[ 11 ]和BERT [ 12 ]（来自 Transformer 的双向编码器表示）。\")\n",
    "\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"# 温度调节\\n温度用于控制聊天机器人的输出。温度越高，响应越具创造性。\")\n",
    "        temperature_slider = gr.Slider(0.0, 2.0, 1.0, step=0.1, label=\"温度\")\n",
    "\n",
    "    with gr.Row():\n",
    "        sent_button = gr.Button(value=\"发送\")\n",
    "        reset_button = gr.Button(value=\"重置\")\n",
    "\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"# 保存结果\\n当你对结果满意后，点击导出按钮保存结果。\")\n",
    "        export_button = gr.Button(value=\"导出\")\n",
    "\n",
    "    # 连接按钮与函数\n",
    "    sent_button.click(interact_summarization, inputs=[prompt_textbox, article_textbox, temperature_slider], outputs=[chatbot])\n",
    "    reset_button.click(reset, outputs=[chatbot])\n",
    "    export_button.click(export_summarization, inputs=[chatbot, article_textbox])\n",
    "\n",
    "# 启动 Gradio 界面\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "读取内容, 生成摘要"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载对话记录的 JSON 文件\n",
    "with open(\"files/part1.json\", \"r\") as f:\n",
    "    context = json.load(f)\n",
    "\n",
    "chatbot = context['chatbot']  # 获取对话记录\n",
    "article = context['article']  # 获取原始文章\n",
    "summarization = chatbot[0][-1]  # 获取摘要结果\n",
    "\n",
    "# 生成 Gradio 的UI界面\n",
    "with gr.Blocks() as demo:\n",
    "    gr.Markdown(\"# 第1部分：摘要\\n你可以查看文章和摘要！\")\n",
    "    chatbot = gr.Chatbot(value=context['chatbot'])  # 加载对话历史\n",
    "    article_textbox = gr.Textbox(label=\"文章\", interactive=False, value=context['article'])  # 显示原始文章\n",
    "\n",
    "    # 构建展示摘要和原文的部分\n",
    "    with gr.Column():\n",
    "        gr.Markdown(\"# 只是一个检查\")\n",
    "        gr.Textbox(label=\"文章\", value=article, show_copy_button=True)  # 显示并允许复制原文\n",
    "        gr.Textbox(label=\"摘要\", value=summarization, show_copy_button=True)  # 显示并允许复制摘要\n",
    "\n",
    "# 启动 Gradio 界面\n",
    "demo.launch(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 最大的感受deepseek回复的内容似乎有字数的限制，导致生成的摘要不够完整\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
