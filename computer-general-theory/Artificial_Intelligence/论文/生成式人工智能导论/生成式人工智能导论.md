> DEMO
> 论文网站:arxiv.org
## 论文1
1. https://arxiv.org/abs/2205.10643
2. https://openai.com/blog/image-gpt/
3. https://speech.ee.ntu.edu.tw/~tlkagk/courses_MLSD15_2.html
4. https://openai.com/blog/better-language-models/
5. https://arxiv.org/abs/2005.14165
6. Source of image: https://arxiv.org/abs/2203.02155
7. InstructGPT:https://arxiv.org/abs/2203.02155
8. This work is done by 劉記良、許宗嫄 https://arxiv.org/abs/1909.09587
9. chain of thought Ref: https://arxiv.org/abs/2205.11916
10. https://sites.google.com/view/automatic-prompt-engineer
11. https://arxiv.org/abs/2206.03931
12. https://arxiv.org/abs/2309.03409
13. Recursive Reprompting and Revision (Re3) https://arxiv.org/abs/2210.06774
14. https://arxiv.org/abs/2212.08073
15. DERA: Enhancing Large Language Model Completions with Dialog-Enabled Resolving Agents https://arxiv.org/abs/2303.17071
16. Language Models as Zero-Shot Planners https://arxiv.org/abs/2201.07207
17. Inner Monologue: Embodied Reasoning through Planning with Language Models https://innermonologue.github.io/

## 论文2

1. https://arxiv.org/abs/2310.02207
2. Source of image: https://memes.tw/wtf?template=55520
3. 全面評估
https://www.greataiprompts.com/guide/jailbreak-chatgpt/
https://arxiv.org/abs/2310.02446
1. https://arxiv.org/abs/2401.03129
## 论文3
1. Q: plug-in, GPTs 是不是重疊了?
    Open AI 官方對於 prompt 的說明 https://platform.openai.com/docs/guides/prompt-engineering/strategy-write-clear-instructions

  [Prompt Engineering Guide](https://www.promptingguide.ai/zh)

https://www.promptingguide.ai/zh
1. https://arxiv.org/abs/2205.11916
2. https://arxiv.org/abs/2211.01910
3. https://arxiv.org/abs/2305.01937
https://arxiv.org/abs/2310.05657
1.  [https://arxiv.org/pdf/2205.03401.pdf](https://arxiv.org/pdf/2205.03401.pdf)
2. https://arxiv.org/abs/2307.11760
3. https://arxiv.org/abs/2312.16171
4. https://arxiv.org/abs/2206.03931
5. [https://huggingface.co/datasets/empathetic_dialogues](https://huggingface.co/datasets/empathetic_dialogues?fbclid=IwAR39S3gBZgK1C2Ry6jqszso4Ni0g0cM0rxXD3bSFayzoM44Syv4EfCPrxo4) 
6. https://arxiv.org/abs/2309.03409
7. https://arxiv.org/abs/2211.01910
8. https://arxiv.org/abs/2205.03401
9. https://llm.ee.ntu.edu.tw/prompt-benchmark/leaderboard
10. https://chat.openai.com/share/743fd564-9ffe-4260-a665-bb59529c92a1
11. https://arxiv.org/abs/2005.14165
12. http://ai.stanford.edu/blog/understanding-incontext/
13. Ref: https://arxiv.org/abs/2202.12837
14. https://arxiv.org/abs/2303.03846
15. https://storage.googleapis.com/deepmind-media/gemini/gemini_v1_5_report.pdf